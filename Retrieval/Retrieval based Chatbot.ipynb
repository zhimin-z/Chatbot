{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbxs0SweU6cw"
   },
   "source": [
    "# 构建于Ubuntu对话数据集上的基于检索的聊天机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里构建一个基于检索的对话系统，我们会对候选集中的回答和问题进行匹配打分，根据分数的高低进行排序并给出我们选择的最佳回复。\n",
    "\n",
    "完整的数据可以在Google Drive文件夹中找到：https://drive.google.com/open?id=1RIIbsS-vxR7Dlo2_v6FWHDFE7q1XPPgj\n",
    "\n",
    " **要复现文档中的代码，需要执行以下操作：**\n",
    "\n",
    "1) **下载** 以下文件:\n",
    "\n",
    "    - glove.6B.50d.txt (Subfolder GloVe)\n",
    "    - training_10000.csv (Subfolder MAIN FILES)\n",
    "    - validation_1000.csv (Subfolder MAIN FILES)\n",
    "    - testing_same_structure_1000.csv (Subfolder MAIN FILES)\n",
    "    - testing_different_structure_100.csv (Subfolder MAIN FILES)\n",
    "    - saved_model_10000_gpu.pt (Subfolder SAVED MODELS)\n",
    "\n",
    "2) **调整变量大小** ：对于代码中出现的 *num_training_examples*, *num_validation_examples*, *embedding_dim*, *test_dataframe_same_structure*, *test_dataframe_different_structure* 和*saved model file name* 可以根据数据量的大小进行调整\n",
    "\n",
    "3) **调整超参数设置**：具体模型的参数大家可以自己调整，也可以参考SAVED MODELS文件夹下的内容，你可以找到**模型截图**，做和它一样的设定，大家也可以复现本notebook的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "R_yISfUlVbi6",
    "outputId": "e4c7c8ed-cd4a-4d96-b3b3-a365a05cda79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2Q22jGEzVc3x",
    "outputId": "fe84a90e-8601-4c06-a31c-fbc355a46a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GloVe\t'MAIN FILES'  'Original Files'\t'SAVED MODELS'\n"
     ]
    }
   ],
   "source": [
    "!ls /content/gdrive/My\\ Drive/Dialogue\\ Files\\ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "2cWCB3FSaKjJ",
    "outputId": "3aa5dc4f-808d-46d9-9566-24fc2ba89704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 591.8MB 24kB/s \n",
      "tcmalloc: large alloc 1073750016 bytes == 0x6211c000 @  0x7effd0bd42a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
      "\u001b[?25hCollecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 26.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Collecting pillow>=4.1.1 (from torchvision)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 7.2MB/s \n",
      "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
      "  Found existing installation: Pillow 4.0.0\n",
      "    Uninstalling Pillow-4.0.0:\n",
      "      Successfully uninstalled Pillow-4.0.0\n",
      "Successfully installed pillow-5.4.1 torch-1.0.0 torchvision-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxppt52QU6cy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.nn import init\n",
    "import torch.nn.utils.rnn \n",
    "import datetime\n",
    "import operator\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pq3v9MhbU6c1"
   },
   "source": [
    "## 定义helper函数以构建训练和验证过程中的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kp272aqzU6c1"
   },
   "outputs": [],
   "source": [
    "def create_dataframe(csvfile):\n",
    "    dataframe = pd.read_csv(csvfile)\n",
    "    return dataframe\n",
    "\n",
    "def shuffle_dataframe(dataframe):\n",
    "    dataframe.reindex(np.random.permutation(dataframe.index))\n",
    "\n",
    "def create_vocab(dataframe):\n",
    "    vocab = []\n",
    "    word_freq = {}\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        context_cell = row[\"Context\"]\n",
    "        response_cell = row[\"Utterance\"]\n",
    "        \n",
    "        train_words = str(context_cell).split() + str(response_cell).split()\n",
    "        \n",
    "        for word in train_words:\n",
    "          \n",
    "            if word.lower() not in vocab:\n",
    "                vocab.append(word.lower())         \n",
    "                       \n",
    "            if word.lower() not in word_freq:\n",
    "                word_freq[word.lower()] = 1\n",
    "            else:\n",
    "                word_freq[word] += 1\n",
    "    \n",
    "    word_freq_sorted = sorted(word_freq.items(), key=lambda item: item[1], reverse=True)\n",
    "    vocab = [\"<UNK>\"] + [pair[0] for pair in word_freq_sorted]\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "\n",
    "def create_word_to_id(vocab):             \n",
    "    word_to_id = {word: id for id, word in enumerate(vocab)}\n",
    "    \n",
    "    return word_to_id\n",
    "\n",
    "\n",
    "def create_id_to_vec(word_to_id, glovefile): \n",
    "    lines = open(glovefile, 'r').readlines()\n",
    "    id_to_vec = {}\n",
    "    vector = None\n",
    "    \n",
    "    for line in lines:\n",
    "        word = line.split()[0]\n",
    "        vector = np.array(line.split()[1:], dtype='float32') #32\n",
    "        \n",
    "        if word in word_to_id:\n",
    "            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(vector))\n",
    "            \n",
    "    for word, id in word_to_id.items(): \n",
    "        if word_to_id[word] not in id_to_vec:\n",
    "            v = np.zeros(*vector.shape, dtype='float32')\n",
    "            v[:] = np.random.randn(*v.shape)*0.01\n",
    "            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(v))\n",
    "            \n",
    "    embedding_dim = id_to_vec[0].shape[0]\n",
    "    \n",
    "    return id_to_vec, embedding_dim\n",
    "\n",
    "\n",
    "def load_ids_and_labels(row, word_to_id):\n",
    "    context_ids = []\n",
    "    response_ids = []\n",
    "\n",
    "    context_cell = row['Context']\n",
    "    response_cell = row['Utterance']\n",
    "    label_cell = row['Label']\n",
    "\n",
    "    max_context_len = 160\n",
    "    \n",
    "    context_words = context_cell.split()\n",
    "    if len(context_words) > max_context_len:\n",
    "        context_words = context_words[:max_context_len]\n",
    "    for word in context_words:\n",
    "        if word in word_to_id:\n",
    "            context_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            context_ids.append(0) #UNK\n",
    "    \n",
    "    response_words = response_cell.split()\n",
    "    for word in response_words:\n",
    "        if word in word_to_id:\n",
    "            response_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            response_ids.append(0)\n",
    "    \n",
    "    label = np.array(label_cell).astype(np.float32)\n",
    "\n",
    "    return context_ids, response_ids, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "quO2AatwU6c3"
   },
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ettxS4qdU6c5"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "            emb_size, \n",
    "            hidden_size, \n",
    "            vocab_size, \n",
    "            p_dropout): \n",
    "    \n",
    "            super(Encoder, self).__init__()\n",
    "             \n",
    "            self.emb_size = emb_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.vocab_size = vocab_size\n",
    "            self.p_dropout = p_dropout\n",
    "       \n",
    "            self.embedding = nn.Embedding(self.vocab_size, self.emb_size)\n",
    "            self.lstm = nn.LSTM(self.emb_size, self.hidden_size)\n",
    "            self.dropout_layer = nn.Dropout(self.p_dropout) \n",
    "\n",
    "            self.init_weights()\n",
    "             \n",
    "    def init_weights(self):\n",
    "        init.uniform(self.lstm.weight_ih_l0, a = -0.01, b = 0.01)\n",
    "        init.orthogonal(self.lstm.weight_hh_l0)\n",
    "        self.lstm.weight_ih_l0.requires_grad = True\n",
    "        self.lstm.weight_hh_l0.requires_grad = True\n",
    "        \n",
    "        embedding_weights = torch.FloatTensor(self.vocab_size, self.emb_size)\n",
    "            \n",
    "        for id, vec in id_to_vec.items():\n",
    "            embedding_weights[id] = vec\n",
    "        \n",
    "        self.embedding.weight = nn.Parameter(embedding_weights, requires_grad = True)\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        _, (last_hidden, _) = self.lstm(embeddings) #dimensions: (num_layers * num_directions x batch_size x hidden_size)\n",
    "        last_hidden = self.dropout_layer(last_hidden[-1])#access last lstm layer, dimensions: (batch_size x hidden_size)\n",
    "\n",
    "        return last_hidden\n",
    "\n",
    "    \n",
    "class DualEncoder(nn.Module):\n",
    "     \n",
    "    def __init__(self, encoder):\n",
    "        super(DualEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.hidden_size = self.encoder.hidden_size\n",
    "        M = torch.FloatTensor(self.hidden_size, self.hidden_size)     \n",
    "        init.xavier_normal(M)\n",
    "        self.M = nn.Parameter(M, requires_grad = True)\n",
    "\n",
    "    def forward(self, context_tensor, response_tensor):\n",
    "        \n",
    "        context_last_hidden = self.encoder(context_tensor) #dimensions: (batch_size x hidden_size)\n",
    "        response_last_hidden = self.encoder(response_tensor) #dimensions: (batch_size x hidden_size)\n",
    "        \n",
    "        #context = context_last_hidden.mm(self.M).cuda()\n",
    "        context = context_last_hidden.mm(self.M) #dimensions: (batch_size x hidden_size)\n",
    "        context = context.view(-1, 1, self.hidden_size) #dimensions: (batch_size x 1 x hidden_size)\n",
    "        \n",
    "        response = response_last_hidden.view(-1, self.hidden_size, 1) #dimensions: (batch_size x hidden_size x 1)\n",
    "        \n",
    "        #score = torch.bmm(context, response).view(-1, 1).cuda()\n",
    "        score = torch.bmm(context, response).view(-1, 1) #dimensions: (batch_size x 1 x 1) and lastly --> (batch_size x 1)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zPtoCbRCU6c7"
   },
   "source": [
    "## 数据与变量构建\n",
    "**定义函数去调用所有的helper函数，以便完成各种数据和变量初始化，以及部分的预训练词向量加载等**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPXr1ps0U6c8"
   },
   "outputs": [],
   "source": [
    "def creating_variables(num_training_examples, num_validation_examples, embedding_dim):\n",
    "\n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Creating variables for training and validation...\")\n",
    "\n",
    "    training_dataframe = create_dataframe('training_%d.csv' %num_training_examples)\n",
    "    vocab = create_vocab(training_dataframe)\n",
    "    word_to_id = create_word_to_id(vocab)\n",
    "    id_to_vec, emb_dim = create_id_to_vec(word_to_id, 'glove.6B.%dd.txt' %embedding_dim)\n",
    "\n",
    "    validation_dataframe = create_dataframe('validation_%d.csv' %num_validation_examples)\n",
    "\n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Variables created.\\n\")\n",
    "    \n",
    "    return training_dataframe, vocab, word_to_id, id_to_vec, emb_dim, validation_dataframe\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mrHdk_QU6c_"
   },
   "source": [
    "## 模型构建\n",
    "**调用Encoder和DualEncoder去构建模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pm9G_DEZU6c_"
   },
   "outputs": [],
   "source": [
    "def creating_model(hidden_size, p_dropout):\n",
    "\n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Calling model...\")\n",
    "\n",
    "    encoder = Encoder(\n",
    "            emb_size = emb_dim,\n",
    "            hidden_size = hidden_size,\n",
    "            vocab_size = len(vocab),\n",
    "            p_dropout = p_dropout)\n",
    "\n",
    "    dual_encoder = DualEncoder(encoder)\n",
    "\n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Model created.\\n\")\n",
    "    print(dual_encoder)\n",
    "    \n",
    "    return encoder, dual_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "306ydgQxU6dC"
   },
   "source": [
    "**训练集和验证集准确率计算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0CNaYhVXU6dC"
   },
   "outputs": [],
   "source": [
    "def increase_count(correct_count, score, label):\n",
    "    if ((score.data[0][0] >= 0.5) and (label.data[0][0] == 1.0)) or ((score.data[0][0] < 0.5) and (label.data[0][0]  == 0.0)):\n",
    "       correct_count +=1  \n",
    "   \n",
    "    return correct_count\n",
    "\n",
    "def get_accuracy(correct_count, dataframe):\n",
    "    accuracy = correct_count/(len(dataframe))\n",
    "        \n",
    "    return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KO-nK9o3U6dF"
   },
   "source": [
    "## 模型训练\n",
    "构建模型训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9C_p51GMU6dF"
   },
   "outputs": [],
   "source": [
    "def train_model(learning_rate, l2_penalty, epochs): \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Starting training and validation...\\n\")\n",
    "    print(\"====================Data and Hyperparameter Overview====================\\n\")\n",
    "    print(\"Number of training examples: %d, Number of validation examples: %d\" %(len(training_dataframe), len(validation_dataframe)))\n",
    "    print(\"Learning rate: %.5f, Embedding Dimension: %d, Hidden Size: %d, Dropout: %.2f, L2:%.10f\\n\" %(learning_rate, emb_dim, encoder.hidden_size, encoder.p_dropout, l2_penalty))\n",
    "    print(\"================================Results...==============================\\n\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(dual_encoder.parameters(), lr = learning_rate, weight_decay = l2_penalty)\n",
    "       \n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    #loss_func.cuda()\n",
    "     \n",
    "    best_validation_accuracy = 0.0\n",
    "     \n",
    "    for epoch in range(epochs):\n",
    "                     \n",
    "            shuffle_dataframe(training_dataframe)\n",
    "                        \n",
    "            sum_loss_training = 0.0\n",
    "            \n",
    "            training_correct_count = 0\n",
    "            \n",
    "            dual_encoder.train()\n",
    "\n",
    "            for index, row in training_dataframe.iterrows():            \n",
    "            \n",
    "                context_ids, response_ids, label = load_ids_and_labels(row, word_to_id)\n",
    "                \n",
    "                context = autograd.Variable(torch.LongTensor(context_ids).view(-1,1), requires_grad = False) #.cuda()\n",
    "                \n",
    "                response = autograd.Variable(torch.LongTensor(response_ids).view(-1, 1), requires_grad = False) #.cuda()\n",
    "                                \n",
    "                label = autograd.Variable(torch.FloatTensor(torch.from_numpy(np.array(label).reshape(1,1))), requires_grad = False) #.cuda()\n",
    "                             \n",
    "                score = dual_encoder(context, response)\n",
    "        \n",
    "                loss = loss_func(score, label)\n",
    "                \n",
    "                sum_loss_training += loss.data[0]\n",
    "                \n",
    "                loss.backward()\n",
    "        \n",
    "                optimizer.step()\n",
    "               \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                training_correct_count = increase_count(training_correct_count, score, label)\n",
    "                                                    \n",
    "            training_accuracy = get_accuracy(training_correct_count, training_dataframe)\n",
    "            \n",
    "            #plt.plot(epoch, training_accuracy)\n",
    "                \n",
    "            shuffle_dataframe(validation_dataframe)\n",
    "            \n",
    "            validation_correct_count = 0\n",
    "\n",
    "            sum_loss_validation = 0.0\n",
    "\n",
    "            dual_encoder.eval()\n",
    "\n",
    "            for index, row in validation_dataframe.iterrows():\n",
    "                \n",
    "                context_ids, response_ids, label = load_ids_and_labels(row, word_to_id)\n",
    "                \n",
    "                context = autograd.Variable(torch.LongTensor(context_ids).view(-1,1)) #.cuda()\n",
    "                \n",
    "                response = autograd.Variable(torch.LongTensor(response_ids).view(-1, 1)) #.cuda()\n",
    "                                \n",
    "                label = autograd.Variable(torch.FloatTensor(torch.from_numpy(np.array(label).reshape(1,1)))) #.cuda()\n",
    "                \n",
    "                score = dual_encoder(context, response)\n",
    "                \n",
    "                loss = loss_func(score, label)\n",
    "                \n",
    "                sum_loss_validation += loss.data[0]\n",
    "                \n",
    "                validation_correct_count = increase_count(validation_correct_count, score, label)\n",
    "                    \n",
    "            validation_accuracy = get_accuracy(validation_correct_count, validation_dataframe)\n",
    "                        \n",
    "            print(str(datetime.datetime.now()).split('.')[0], \n",
    "                  \"Epoch: %d/%d\" %(epoch,epochs),  \n",
    "                  \"TrainLoss: %.3f\" %(sum_loss_training/len(training_dataframe)), \n",
    "                  \"TrainAccuracy: %.3f\" %(training_accuracy), \n",
    "                  \"ValLoss: %.3f\" %(sum_loss_validation/len(validation_dataframe)), \n",
    "                  \"ValAccuracy: %.3f\" %(validation_accuracy))\n",
    "            \n",
    "            if validation_accuracy > best_validation_accuracy:\n",
    "                best_validation_accuracy = validation_accuracy\n",
    "                torch.save(dual_encoder.state_dict(), 'saved_model_%d_examples.pt' %(len(training_dataframe)))\n",
    "                print(\"New best found and saved.\")\n",
    "                \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Training and validation epochs finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uuttvu5qU6dK"
   },
   "outputs": [],
   "source": [
    "training_dataframe, vocab, word_to_id, id_to_vec, emb_dim, validation_dataframe = creating_variables(num_training_examples = 10000, \n",
    "                                                                                                     embedding_dim = 50, \n",
    "                                                                                                     num_validation_examples = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PraKxmygU6dN"
   },
   "source": [
    "**设定hidden size和dropout概率，构建模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ib7ktCiU6dN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder, dual_encoder = creating_model(hidden_size = 50, \n",
    "                                       p_dropout = 0.85)\n",
    "\n",
    "#encoder.cuda()\n",
    "#dual_encoder.cuda\n",
    "\n",
    "for name, param in dual_encoder.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFVZf8cSU6dQ"
   },
   "source": [
    "**设定学习率，迭代轮数，l2正则化强度，开始训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSdLwUivU6dR"
   },
   "outputs": [],
   "source": [
    "train_model(learning_rate = 0.0001, \n",
    "            l2_penalty = 0.0001,\n",
    "            epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Of2CvJHU6dS"
   },
   "source": [
    "**加载训练好的模型进行测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXL_0KT3U6dT"
   },
   "outputs": [],
   "source": [
    "dual_encoder.load_state_dict(torch.load('saved_model_10000_examples.pt'))\n",
    "\n",
    "dual_encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbsXLlbjU6dW"
   },
   "source": [
    "**第1种测试方式:**\n",
    "\n",
    "*测试数据集和训练还有验证数据集有着一样的数据组织格式 (context, response, label)*\n",
    "\n",
    "*测试评判指标：准确率*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90kzKiEvU6dW"
   },
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGl4gMQtU6dW"
   },
   "outputs": [],
   "source": [
    "test_dataframe_same_structure = pd.read_csv('testing_same_structure_1000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6l8g-9cU6dY"
   },
   "source": [
    "构建测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlBkcuiEU6da"
   },
   "outputs": [],
   "source": [
    "def testing_same_structure():\n",
    "    \n",
    "    test_correct_count = 0\n",
    "\n",
    "    for index, row in test_dataframe_same_structure.iterrows():\n",
    "\n",
    "        context_ids, response_ids, label = load_ids_and_labels(row, word_to_id)\n",
    "\n",
    "        context = autograd.Variable(torch.LongTensor(context_ids).view(-1,1)) #.cuda()\n",
    "\n",
    "        response = autograd.Variable(torch.LongTensor(response_ids).view(-1, 1)) #.cuda()\n",
    "\n",
    "        label = autograd.Variable(torch.FloatTensor(torch.from_numpy(np.array(label).reshape(1,1)))) #.cuda()\n",
    "\n",
    "        score = dual_encoder(context, response)\n",
    "\n",
    "        test_correct_count = increase_count(test_correct_count, score, label)\n",
    "\n",
    "    test_accuracy = get_accuracy(test_correct_count, test_dataframe_same_structure)\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "krVSNO2IU6dd"
   },
   "source": [
    "准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxAgtA5iU6de"
   },
   "outputs": [],
   "source": [
    "test_accuracy = testing_same_structure()\n",
    "print(\"Test accuracy for %d training examples and %d test examples: %.2f\" %(len(training_dataframe),len(test_dataframe_same_structure),test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v3CBqVMGU6dh"
   },
   "source": [
    "**第2种测试方式**\n",
    "\n",
    "*测试数据集和训练/验证集格式不一样 (1个问题，1个标准答案，9个干扰项错误答案)*\n",
    "\n",
    "*测试评估指标：recall(召回)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZxTHghYyU6di"
   },
   "source": [
    "加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Fciv3mWU6dj"
   },
   "outputs": [],
   "source": [
    "test_dataframe_different_structure = pd.read_csv('testing_different_structure_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5h91-fyqU6dl"
   },
   "source": [
    "以字典形态存储对话word ids\n",
    "\n",
    "*Outer dictionary \"ids_per_example_and_candidate\": keys = examples, values = inner dictionaries*\n",
    "\n",
    "*Inner dictionaries \"ids_per_candidate\": keys = candidate names, values = list of word IDs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jq_kr4TCU6dl"
   },
   "outputs": [],
   "source": [
    "def load_ids(test_dataframe_different_structure, word_to_id):\n",
    "    \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Loading test IDs...\")\n",
    "\n",
    "    max_context_len = 160\n",
    "    \n",
    "    ids_per_example_and_candidate = {}\n",
    "    \n",
    "    for i, example in test_dataframe_different_structure.iterrows():\n",
    "        \n",
    "        ids_per_candidate = {}\n",
    "      \n",
    "        for column_name, cell in  example.iteritems():\n",
    "            \n",
    "                id_list = []\n",
    "            \n",
    "                words = str(cell).split()\n",
    "                if len(words) > max_context_len:\n",
    "                    words = words[:max_context_len]\n",
    "    \n",
    "                for word in words:\n",
    "                    if word in word_to_id:\n",
    "                        id_list.append(word_to_id[word])\n",
    "                    else: \n",
    "                        id_list.append(0) #UNK  \n",
    "                    \n",
    "                ids_per_candidate[column_name] = id_list\n",
    "    \n",
    "        ids_per_example_and_candidate[i] = ids_per_candidate\n",
    "    \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Test IDs loaded.\")\n",
    "    \n",
    "    return ids_per_example_and_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pki-Uj6pU6dn"
   },
   "outputs": [],
   "source": [
    "ids_per_example_and_candidate = load_ids(test_dataframe_different_structure, word_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NlAXC2N3U6dq"
   },
   "source": [
    "以字典形态存储得分score\n",
    "\n",
    "*Outer dictionary \"scores_per_example_and_candidate\": keys = examples, values = inner dictionaries*\n",
    "\n",
    "*Inner dictionaries \"scores_per_candidate\": keys = candidate names, values = score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q1sj_4tiU6dv"
   },
   "outputs": [],
   "source": [
    "def load_scores(): \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Computing test scores...\")\n",
    "    \n",
    "    scores_per_example_and_candidate = {}\n",
    "                 \n",
    "    for example, utterance_ids_dict in sorted(ids_per_example_and_candidate.items()): \n",
    "        \n",
    "        score_per_candidate = {}\n",
    "\n",
    "        for utterance_name, ids_list in sorted(utterance_ids_dict.items()):\n",
    "        \n",
    "            context = autograd.Variable(torch.LongTensor(utterance_ids_dict['Context']).view(-1,1))#.cuda()\n",
    "            \n",
    "            if utterance_name != 'Context':\n",
    "\n",
    "                candidate_response = autograd.Variable(torch.LongTensor(utterance_ids_dict[utterance_name]).view(-1, 1))#.cuda()\n",
    "                        \n",
    "                score = torch.sigmoid(dual_encoder(context, candidate_response))\n",
    "                \n",
    "                score_per_candidate[\"Score with \" + utterance_name] = score.data[0][0]\n",
    "    \n",
    "        scores_per_example_and_candidate[example] = score_per_candidate\n",
    "\n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Test scores computed.\")\n",
    "    \n",
    "    return scores_per_example_and_candidate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tRtL5DiuU6dw"
   },
   "outputs": [],
   "source": [
    "scores_per_example_and_candidate = load_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUWC8Vn3U6dy"
   },
   "source": [
    "定义计算召回结果的方法： \n",
    "\n",
    "这里计算的是recall@k这个评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1T-OzFvU6dz"
   },
   "outputs": [],
   "source": [
    "def get_recall_at_k(k):\n",
    "    count_true_hits = 0\n",
    "    \n",
    "    for example, score_per_candidate_dict in sorted(scores_per_example_and_candidate.items()): \n",
    "    \n",
    "        top_k = dict(sorted(score_per_candidate_dict.items(), key=operator.itemgetter(1), reverse=True)[:k])\n",
    "        \n",
    "        if 'Score with Ground Truth Utterance' in top_k:\n",
    "            count_true_hits += 1\n",
    "    \n",
    "    number_of_examples = len(scores_per_example_and_candidate)\n",
    "    \n",
    "    recall_at_k = count_true_hits/number_of_examples\n",
    "    \n",
    "    return recall_at_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9p4gjOCU6d1"
   },
   "outputs": [],
   "source": [
    "print(\"recall_at_5 =\",get_recall_at_k(k = 5)) #Baseline expectation: 5/10 = 0.5 for random guess\n",
    "print(\"recall_at_2 =\",get_recall_at_k(k = 2)) #Baseline expectation: 2/10 = 0.2 for random guess\n",
    "print(\"recall_at_1 =\",get_recall_at_k(k = 1)) #Baseline expectation: 1/10 = 0.1 for random guess"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_Dialog_System_Notebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
